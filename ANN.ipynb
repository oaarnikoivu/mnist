{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, inputnodes=784, hiddennodes=200, outputnodes=10, learningrate=0.1, batch_size=1, epochs=10):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "\n",
    "        self.wih = np.random.normal(\n",
    "            0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(\n",
    "            0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # set the learning rate\n",
    "        self.lr = learningrate\n",
    "\n",
    "        # set the batch size\n",
    "        self.bs = batch_size\n",
    "\n",
    "        # set the number of epochs\n",
    "        self.ep = epochs\n",
    "\n",
    "        self.E = []\n",
    "\n",
    "        self.results = []\n",
    "\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        self.activations = []\n",
    "        \n",
    "        self.encoded_images = []\n",
    "        \n",
    "        self.decoded_images = []\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def batch_input(self, X, y):  # (self, train_inputs, targets):\n",
    "        for i in range(0, len(X), self.bs):\n",
    "            yield (X[i:i + self.bs], y[i:i + self.bs])\n",
    "\n",
    "    def train(self, train_inputs, targets_list):\n",
    "        for e in range(self.ep):\n",
    "            print(\"Training epoch#: \", e)\n",
    "\n",
    "            sum_error = 0.0\n",
    "\n",
    "            for (batchX, batchY) in self.batch_input(train_inputs, targets_list):\n",
    "                # creating variables to store the gradients\n",
    "                delta_who = 0\n",
    "                delta_wih = 0\n",
    "\n",
    "                # iterate through the inputs sent in\n",
    "                for inputs, targets in zip(batchX, batchY):\n",
    "                    # convert  inputs list to 2d array\n",
    "                    inputs = np.array(inputs,  ndmin=2).T\n",
    "                    targets = np.array(targets, ndmin=2).T\n",
    "\n",
    "                    # calculate signals into hidden layer\n",
    "                    hidden_inputs = np.dot(self.wih, inputs)\n",
    "                    # calculate the signals emerging from the hidden layer\n",
    "                    hidden_outputs = self.activation_function(hidden_inputs)\n",
    "                    \n",
    "                    ## store hidden activations\n",
    "                    self.activations.append(hidden_outputs.flatten())\n",
    "\n",
    "                    # calculate signals into final output layer\n",
    "                    final_inputs = np.dot(self.who, hidden_outputs)\n",
    "                                    \n",
    "                    self.encoded_images.append(final_inputs)\n",
    "                    \n",
    "                    # calculate the signals emerging from final output layer\n",
    "                    final_outputs = self.activation_function(final_inputs)\n",
    "                    \n",
    "                    # uncomment below for Task5!\n",
    "                    self.decoded_images.append(final_outputs)\n",
    "\n",
    "                    # to calculate the error we need to compute the element wise diff between target and actual\n",
    "                    output_errors = targets - final_outputs\n",
    "\n",
    "                    # Next distribute the error to the hidden layer such that hidden layer error\n",
    "                    # is the output_errors, split by weights, recombined at hidden nodes\n",
    "                    hidden_errors = np.dot(self.who.T, output_errors)\n",
    "\n",
    "                    # for each instance accumilate the gradients from each instance\n",
    "                    # delta_who are the gradients between hidden and output weights\n",
    "                    # delta_wih are the gradients between input and hidden weights\n",
    "                    delta_who += np.dot((output_errors * final_outputs *\n",
    "                                         (1.0 - final_outputs)), np.transpose(hidden_outputs))\n",
    "                    delta_wih += np.dot((hidden_errors * hidden_outputs *\n",
    "                                         (1.0 - hidden_outputs)), np.transpose(inputs))\n",
    "\n",
    "                    # this is the sum of squared error accumilated over each batced instance\n",
    "                    sum_error += np.dot(output_errors.T, output_errors)\n",
    "                pass  # instance\n",
    "\n",
    "                # update the weights by multiplying the gradient with the learning rate\n",
    "                # note that the deltas are divided by batch size to obtain the average gradient according to the given batch\n",
    "                # obviously if batch size = 1 then we simply end up dividing by 1 since each instance forms a singleton batch\n",
    "                self.who += self.lr * (delta_who / self.bs)\n",
    "                self.wih += self.lr * (delta_wih / self.bs)\n",
    "            pass  # batch\n",
    "            self.E.append(np.asfarray(sum_error).flatten())\n",
    "            print(\"errors (SSE): \", self.E[-1])\n",
    "        pass  # epoch\n",
    "    \n",
    "        ## return the activations from the last epoch\n",
    "        return self.activations[-len(train_inputs):]\n",
    "    \n",
    "    ## Encode\n",
    "    def encode(self, inputs_list):\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "\n",
    "        # propogate input into hidden layer. This is the start of the forward pass\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "\n",
    "        # squash the content in the hidden node using the sigmoid function (value between 1, -1)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        return hidden_outputs.flatten()\n",
    "    \n",
    "    def query(self, inputs_list):\n",
    "\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "\n",
    "        # propogate input into hidden layer. This is the start of the forward pass\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "\n",
    "        # squash the content in the hidden node using the sigmoid function (value between 1, -1)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        # propagate into output layer and the apply the squashing sigmoid function\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        return final_outputs\n",
    "\n",
    "    def test(self, test_inputs, test_targets):\n",
    "        self.results = []\n",
    "\n",
    "        # go through each test instances\n",
    "        for inputs, target in zip(test_inputs, test_targets):\n",
    "            # query the network with test inputs\n",
    "            # note this returns 10 output values ; of which the index of the highest value\n",
    "            # is the networks predicted class label\n",
    "            outputs = self.query(inputs)\n",
    "            # get the target which has 0.99 as highest value corresponding to the actual class\n",
    "            target_label = np.argmax(target)\n",
    "            # get the index of the highest output node as this corresponds to the predicted class\n",
    "            # this is the class predicted by the ANN\n",
    "            predict_label = np.argmax(outputs)\n",
    "\n",
    "            self.results.append([predict_label, target_label])\n",
    "            pass\n",
    "        pass\n",
    "        # flatten results to avoid nested arrays\n",
    "        self.results = np.asfarray(self.results)\n",
    "\n",
    "    def evaluate(self, results):\n",
    "        correct = 0\n",
    "        for result in results:\n",
    "            if result[0] == result[1]:\n",
    "                correct += 1\n",
    "        return 100 * (correct / len(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
