{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "%run utils.ipynb\n",
    "%run preprocess.ipynb\n",
    "%run ANN.ipynb\n",
    "%run kNN.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to show correct and incorrect predictions\n",
    "def show_results(results):\n",
    "    print('Correct predictions: ')\n",
    "    for pred, target in results:\n",
    "        if pred == target:\n",
    "            print(\"Predicted: \", pred, \" Input: \", target)\n",
    "    \n",
    "    print('\\nIncorrect predictions: ')\n",
    "    for pred, target in results:\n",
    "        if pred != target:\n",
    "            print(\"Predicted: \", pred, \" Input: \", target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"mnist_train.csv\"\n",
    "test_file = \"mnist_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size:  60000\n",
      "test set size:  10000\n"
     ]
    }
   ],
   "source": [
    "train_data_file = open(train_file, 'r')\n",
    "train_data_list = train_data_file.readlines() \n",
    "train_data_file.close() \n",
    "print(\"train set size: \", len(train_data_list))\n",
    "\n",
    "test_data_file = open(test_file, 'r') \n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "print(\"test set size: \", len(test_data_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set our preprocessing class for the ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Preprocess(is_neural=True) # Preprocess object for ANN\n",
    "\n",
    "mini_training_data = p.generate_mini_data(train_data_list, 1500)\n",
    "X_train, y_train = p.preprocess_data(mini_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GIMP digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gimp/*.png\n",
      "Loading...  gimp/gimp_2.png\n",
      "Loading...  gimp/gimo_6.png\n",
      "Loading...  gimp/gimp_3.png\n",
      "Loading...  gimp/gimp_1.png\n",
      "Loading...  gimp/gimp_0.png\n",
      "Loading...  gimp/gimp_4.png\n",
      "Loading...  gimp/gimp_5.png\n",
      "Loading...  gimp/gimp_7.png\n",
      "Loading...  gimp/gimp_8.png\n",
      "Loading...  gimp/gimp_9.png\n"
     ]
    }
   ],
   "source": [
    "gimp_test_X, gimp_test_y = get_my_test_data(\"gimp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.asfarray(gimp_test_X[1].flatten().reshape((28,28))), cmap='Greys', interpolation='None')\n",
    "\n",
    "plt.title('GIMP')\n",
    "\n",
    "plt.savefig('gimp-digit', dpi=300)\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gimp_test_X, gimp_test_y = map_target_to_output_layer(gimp_test_X, gimp_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "We use the optimal hyperparameters obtained from Task1.\n",
    "\n",
    "- 50 epochs\n",
    "- learning rate = 0.3\n",
    "- batch size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch#:  0\n",
      "errors (SSE):  [535.80374548]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [205.72002754]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [115.48252849]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [64.07616103]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [38.17151961]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [24.65231101]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [16.76377641]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [12.10412825]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [9.14612284]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [7.28841553]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [5.97014897]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [5.02562921]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [4.34893479]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [3.8300955]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [3.41236939]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [3.07155225]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [2.7971083]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [2.57841895]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [2.401132]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [2.24164711]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [2.10494179]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [1.98471361]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [1.87588731]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [1.77756535]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [1.6891833]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [1.60853636]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [1.53416915]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [1.46586057]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [1.40340383]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [1.34610085]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [1.29299205]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [1.24319004]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [1.19613098]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [1.15185231]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [1.11084827]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [1.07428449]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [1.04180028]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [1.01240163]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [0.9853669]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [0.96028993]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [0.9368603]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [0.91476665]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [0.89375574]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [0.87370672]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [0.85457828]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [0.8363354]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [0.81892189]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [0.80225508]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [0.78625142]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [0.77086024]\n"
     ]
    }
   ],
   "source": [
    "n = NeuralNetwork(epochs=50, learningrate=0.3, batch_size=1)\n",
    "n.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ANN model accuracy on GIMP digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on GIMP digits % =  80.0\n"
     ]
    }
   ],
   "source": [
    "n.test(gimp_test_X, gimp_test_y)\n",
    "ann_gimp_acc = n.evaluate(n.results)\n",
    "\n",
    "print('Accuracy on GIMP digits % = ', ann_gimp_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which values our model predicted correctly and incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions: \n",
      "Predicted:  2.0  Input:  2.0\n",
      "Predicted:  3.0  Input:  3.0\n",
      "Predicted:  1.0  Input:  1.0\n",
      "Predicted:  0.0  Input:  0.0\n",
      "Predicted:  4.0  Input:  4.0\n",
      "Predicted:  5.0  Input:  5.0\n",
      "Predicted:  7.0  Input:  7.0\n",
      "Predicted:  8.0  Input:  8.0\n",
      "\n",
      "Incorrect predictions: \n",
      "Predicted:  5.0  Input:  6.0\n",
      "Predicted:  7.0  Input:  9.0\n"
     ]
    }
   ],
   "source": [
    "show_results(n.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the digits that were written using GIMP look slightly rotated, let's see if a model trained on rotated images performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run augment.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AugmentImages(is_neural=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Its possible that some of the GIMP digits are slightly rotated so we test if training our model on rotated images improves performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling data...\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [564.09248384]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [235.41485947]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [136.84255968]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [81.03545402]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [51.79737301]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [31.09549694]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [19.58772098]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [14.03786269]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [10.72206244]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [8.60838711]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [7.10595597]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [6.02478492]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [5.2227149]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [4.61081828]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [4.13099083]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [3.74316587]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [3.42154503]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [3.14900413]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [2.91572404]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [2.71494925]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [2.54099943]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [2.38875656]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [2.25376813]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [2.13341664]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [2.02640122]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [1.93085409]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [1.84434631]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [1.76501575]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [1.69205184]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [1.62490237]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [1.56283254]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [1.50524853]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [1.45178135]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [1.40211047]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [1.35591743]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [1.3128992]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [1.27277815]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [1.2353087]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [1.20028247]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [1.16752584]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [1.13688793]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [1.10822476]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [1.08137845]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [1.05614391]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [1.03222855]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [1.00924249]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [0.98682507]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [0.9649613]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [0.94390157]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [0.92364064]\n",
      "Shuffling data...\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [693.83345528]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [354.46258674]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [216.29783807]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [130.21801394]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [75.68706254]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [47.3609538]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [31.12128317]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [21.75206967]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [16.21237236]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [12.71899919]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [10.30566065]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [8.68174908]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [7.50162365]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [6.60541151]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [5.91072282]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [5.3613757]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [4.91250909]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [4.53624886]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [4.21256325]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [3.9241041]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [3.68545648]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [3.48625329]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [3.31015092]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [3.14941329]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [2.99737978]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [2.85438503]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [2.72694895]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [2.60787482]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [2.50531039]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [2.41331026]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [2.32917594]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [2.25090582]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [2.17691316]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [2.10745222]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [2.04405353]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [1.98716393]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [1.93193679]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [1.85451356]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [1.78224922]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [1.72266805]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [1.67254352]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [1.6300237]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [1.60001092]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [1.56043791]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [1.49745451]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [1.45791745]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [1.42748114]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [1.39962193]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [1.37316896]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [1.34786009]\n",
      "Shuffling data...\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [772.52742]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [403.96070823]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [260.00888123]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [172.15363871]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [111.85657609]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [68.66707205]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [46.41320141]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [31.608236]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [21.6900721]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [15.76540437]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [12.17518807]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [9.87585824]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [8.32619995]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [7.22152224]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [6.38122629]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [5.72993722]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [5.22917734]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [4.82275422]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [4.38326502]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [4.07336749]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [3.81850882]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [3.59209377]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [3.390817]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [3.21228058]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [3.05626683]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [2.91916196]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [2.79507236]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [2.67777896]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [2.57240633]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [2.47387956]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [2.38054951]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [2.29361715]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [2.21366811]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [2.14041229]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [2.07292639]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [2.01040369]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [1.95208965]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [1.89778725]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [1.8474599]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [1.80088106]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [1.75794779]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [1.71819809]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [1.68036629]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [1.64236709]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [1.60565682]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [1.57244194]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [1.54223555]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [1.51407659]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [1.48704262]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [1.46048124]\n",
      "Shuffling data...\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [843.8304509]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [448.69717657]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [285.32715744]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [180.58462442]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [111.72671676]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [70.97790314]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [45.68492348]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [31.03251018]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [21.95969067]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [16.47906334]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [12.81768217]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [10.31417632]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [8.61901781]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [7.45304749]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [6.60671218]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [5.91303333]\n",
      "Training epoch#:  16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors (SSE):  [5.35640955]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [4.92551526]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [4.58125078]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [4.2734517]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [4.01128698]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [3.78094919]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [3.57451538]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [3.39156879]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [3.23450115]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [3.0978237]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [2.97844592]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [2.86966316]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [2.76145041]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [2.64467942]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [2.54175625]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [2.45168712]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [2.36861536]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [2.29219667]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [2.22240961]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [2.15828421]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [2.09778848]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [2.0392773]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [1.98332876]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [1.93232107]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [1.88612478]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [1.84096711]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [1.79585464]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [1.75035518]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [1.70750376]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [1.66955835]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [1.63468044]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [1.60354365]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [1.57479955]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [1.54783594]\n"
     ]
    }
   ],
   "source": [
    "ann_gimp_aug_results = []\n",
    "\n",
    "# We test on different rotations and record the best result.\n",
    "rotations = [10, 20, 30, 45]\n",
    "\n",
    "for num in rotations:\n",
    "     ## Clear and generate data again\n",
    "    mini_training_data = p.generate_mini_data(train_data_list, 1500)\n",
    "\n",
    "    X_train, y_train = p.preprocess_data(mini_training_data)\n",
    "    \n",
    "    ## train and test model on gimp digits\n",
    "    model = a.fit_augmented_model(X_train, y_train, gimp_test_X, gimp_test_y, 1500, num)\n",
    "    \n",
    "    ann_gimp_aug_results.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get 90% for images rotated up to 20Â°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70.0, 90.0, 80.0, 50.0]\n",
      "72.5\n"
     ]
    }
   ],
   "source": [
    "print(ann_gimp_aug_results)\n",
    "print(statistics.mean(ann_gimp_aug_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load digits written on whiteboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hw_digits/*.png\n",
      "Loading...  hw_digits/img_1.png\n",
      "Loading...  hw_digits/img_2.png\n",
      "Loading...  hw_digits/img_3.png\n",
      "Loading...  hw_digits/img_7.png\n",
      "Loading...  hw_digits/img_6.png\n",
      "Loading...  hw_digits/img_4.png\n",
      "Loading...  hw_digits/img_5.png\n",
      "Loading...  hw_digits/img_8.png\n",
      "Loading...  hw_digits/img_9.png\n"
     ]
    }
   ],
   "source": [
    "hw_digits_X, hw_digits_Y = get_my_test_data(\"hw_digits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.asfarray(hw_digits_X[4].flatten().reshape((28,28))), cmap='Greys', interpolation='None')\n",
    "\n",
    "plt.title('Whiteboard')\n",
    "plt.savefig('hw-digit.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell that this handwritten digit looks unclear in comparison to the digits written with GIMP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_digits_X, hw_digits_Y = map_target_to_output_layer(hw_digits_X, hw_digits_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems as if the iPhone has captured more noise in comparison to the GIMP digits. This is likely due to the quality of the camera and lighting of the room the photos were taken in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array([0.40167892, 0.3982392 , 0.39779657, 0.39779657, 0.39779657,\n",
       "        0.39779657, 0.39779657, 0.40167892, 0.39779657, 0.3994    ,\n",
       "        0.40328234, 0.40556127, 0.40944362, 0.41332597, 0.41104707,\n",
       "        0.41448683, 0.41720834, 0.41720834, 0.42020553, 0.42408788,\n",
       "        0.42408788, 0.42797023, 0.42685214, 0.4307345 , 0.43894175,\n",
       "        0.4428241 , 0.4462639 , 0.45014626, 0.40167892, 0.40167892,\n",
       "        0.40167892, 0.40167892, 0.40167892, 0.40212154, 0.3982392 ,\n",
       "        0.40167892, 0.40167892, 0.40167892, 0.40167892, 0.40944362,\n",
       "        0.41332597, 0.41332597, 0.41104707, 0.40944362, 0.41720834,\n",
       "        0.41720834, 0.4206481 , 0.42408788, 0.42797023, 0.43185258,\n",
       "        0.43301338, 0.43461683, 0.4428241 , 0.44238153, 0.4462639 ,\n",
       "        0.4462639 , 0.40556127, 0.40556127, 0.40167892, 0.40556127,\n",
       "        0.40167892, 0.40212154, 0.3994    , 0.39779657, 0.40328234,\n",
       "        0.4060039 , 0.40944362, 0.40716472, 0.44286683, 0.48200873,\n",
       "        0.40832552, 0.41448683, 0.41609022, 0.4210907 , 0.42020553,\n",
       "        0.42408788, 0.42524865, 0.42957366, 0.43849918, 0.43461683,\n",
       "        0.43894175, 0.44238153, 0.4432667 , 0.4432667 , 0.40556127,\n",
       "        0.4060039 , 0.40167892, 0.40556127, 0.40167892, 0.40556127,\n",
       "        0.40167892, 0.40328234, 0.40167892, 0.40556127, 0.40944362,\n",
       "        0.40944362, 0.50186306, 0.77203596, 0.4129261 , 0.4179266 ,\n",
       "        0.4213663 , 0.41748396, 0.4179266 , 0.42180896, 0.42957366,\n",
       "        0.4307345 , 0.4307345 , 0.43461683, 0.43849918, 0.43938434,\n",
       "        0.43938434, 0.4432667 , 0.40944362, 0.40944362, 0.40556127,\n",
       "        0.40167892, 0.40556127, 0.40556127, 0.40328234, 0.40556127,\n",
       "        0.40944362, 0.40944362, 0.40944362, 0.40944362, 0.45291045,\n",
       "        0.81518835, 0.45478952, 0.41748396, 0.41520506, 0.41720834,\n",
       "        0.42180896, 0.4307345 , 0.4307345 , 0.42685214, 0.43461683,\n",
       "        0.43461683, 0.43849918, 0.43938434, 0.4428241 , 0.4432667 ,\n",
       "        0.40716472, 0.40944362, 0.40556127, 0.40944362, 0.40556127,\n",
       "        0.40556127, 0.40556127, 0.40556127, 0.41332597, 0.41448683,\n",
       "        0.41448683, 0.41448683, 0.4385419 , 0.8035413 , 0.47120413,\n",
       "        0.41448683, 0.4206481 , 0.42453045, 0.42613387, 0.42957366,\n",
       "        0.4307345 , 0.4307345 , 0.4307345 , 0.44238153, 0.43894175,\n",
       "        0.43938434, 0.4432667 , 0.4432667 , 0.40944362, 0.40944362,\n",
       "        0.41104707, 0.41104707, 0.41332597, 0.41332597, 0.42657647,\n",
       "        0.41720834, 0.41288337, 0.41676575, 0.41564763, 0.41520506,\n",
       "        0.4280129 , 0.79461575, 0.4758047 , 0.41836917, 0.42385495,\n",
       "        0.42657647, 0.42657647, 0.43229514, 0.4307345 , 0.4307345 ,\n",
       "        0.4307345 , 0.4350594 , 0.43161964, 0.4432667 , 0.4432667 ,\n",
       "        0.4432667 , 0.4210907 , 0.41720834, 0.4210907 , 0.41720834,\n",
       "        0.41720834, 0.41720834, 0.43822354, 0.4210907 , 0.42497304,\n",
       "        0.42497304, 0.42453045, 0.42020553, 0.4462639 , 0.7918515 ,\n",
       "        0.48745176, 0.43117705, 0.435502  , 0.435502  , 0.43938434,\n",
       "        0.43161964, 0.43894175, 0.4307345 , 0.4307345 , 0.43461683,\n",
       "        0.43938434, 0.43938434, 0.4432667 , 0.4432667 , 0.4210907 ,\n",
       "        0.4210907 , 0.4288554 , 0.41720834, 0.41720834, 0.4210907 ,\n",
       "        0.42225152, 0.42497304, 0.42497304, 0.42497304, 0.42453045,\n",
       "        0.4213663 , 0.45907176, 0.78685105, 0.47624725, 0.4350594 ,\n",
       "        0.43161964, 0.435502  , 0.43938434, 0.43938434, 0.435502  ,\n",
       "        0.4307345 , 0.43117705, 0.43849918, 0.435502  , 0.43938434,\n",
       "        0.4428241 , 0.4462639 , 0.41720834, 0.41720834, 0.41720834,\n",
       "        0.41720834, 0.41720834, 0.42020553, 0.42408788, 0.42453045,\n",
       "        0.42497304, 0.4288554 , 0.4288554 , 0.42225152, 0.46571836,\n",
       "        0.78685105, 0.4602753 , 0.43461683, 0.43461683, 0.43461683,\n",
       "        0.43461683, 0.43894175, 0.4350594 , 0.4307345 , 0.43117705,\n",
       "        0.4350594 , 0.4350594 , 0.43938434, 0.44670647, 0.4428241 ,\n",
       "        0.41881177, 0.41720834, 0.4210907 , 0.4210907 , 0.41720834,\n",
       "        0.42408788, 0.43345603, 0.43229514, 0.4288554 , 0.4304588 ,\n",
       "        0.4288554 , 0.43001622, 0.47624725, 0.79461575, 0.43510213,\n",
       "        0.4350594 , 0.435502  , 0.435502  , 0.4350594 , 0.43849918,\n",
       "        0.43461683, 0.4307345 , 0.4350594 , 0.43938434, 0.435502  ,\n",
       "        0.435502  , 0.43938434, 0.4432667 , 0.4210907 , 0.42497304,\n",
       "        0.4210907 , 0.4206481 , 0.42408788, 0.42408788, 0.4284128 ,\n",
       "        0.43001622, 0.4304588 , 0.4288554 , 0.43001622, 0.43001622,\n",
       "        0.5080671 , 0.78841174, 0.43050155, 0.435502  , 0.43938434,\n",
       "        0.435502  , 0.4350594 , 0.43849918, 0.43461683, 0.4350594 ,\n",
       "        0.435502  , 0.43938434, 0.435502  , 0.43938434, 0.44238153,\n",
       "        0.44238153, 0.4210907 , 0.4210907 , 0.42453045, 0.42408788,\n",
       "        0.42408788, 0.42408788, 0.42797023, 0.42913103, 0.43001622,\n",
       "        0.43273774, 0.4304588 , 0.43001622, 0.52247834, 0.7185255 ,\n",
       "        0.435502  , 0.435502  , 0.4432667 , 0.43938434, 0.43894175,\n",
       "        0.43894175, 0.43894175, 0.435502  , 0.435502  , 0.43938434,\n",
       "        0.43938434, 0.4350594 , 0.44238153, 0.4428241 , 0.4210907 ,\n",
       "        0.42497304, 0.4206481 , 0.42180896, 0.42408788, 0.4256913 ,\n",
       "        0.4288554 , 0.4288554 , 0.4284128 , 0.42797023, 0.42957366,\n",
       "        0.4284128 , 0.5515766 , 0.6842987 , 0.43938434, 0.43938434,\n",
       "        0.4432667 , 0.43938434, 0.43938434, 0.4432667 , 0.4432667 ,\n",
       "        0.435502  , 0.43938434, 0.435502  , 0.43938434, 0.43894175,\n",
       "        0.43938434, 0.44238153, 0.42497304, 0.4210907 , 0.4256913 ,\n",
       "        0.42913103, 0.43849918, 0.43001622, 0.4304588 , 0.4288554 ,\n",
       "        0.43345603, 0.4307345 , 0.43345603, 0.4343412 , 0.5763072 ,\n",
       "        0.65247893, 0.4421059 , 0.4366201 , 0.43822354, 0.43938434,\n",
       "        0.4432667 , 0.4432667 , 0.4432667 , 0.4432667 , 0.43938434,\n",
       "        0.4432667 , 0.43938434, 0.43938434, 0.43938434, 0.44238153,\n",
       "        0.42497304, 0.42613387, 0.4284128 , 0.43345603, 0.4350594 ,\n",
       "        0.43345603, 0.43001622, 0.43229514, 0.43001622, 0.42957366,\n",
       "        0.43161964, 0.435502  , 0.62070185, 0.61557335, 0.43938434,\n",
       "        0.435502  , 0.43938434, 0.43938434, 0.43938434, 0.4432667 ,\n",
       "        0.44714907, 0.44714907, 0.4432667 , 0.4432667 , 0.4432667 ,\n",
       "        0.4432667 , 0.43938434, 0.43938434, 0.42453045, 0.42613387,\n",
       "        0.4288554 , 0.43273774, 0.43001622, 0.43894175, 0.4307345 ,\n",
       "        0.4307345 , 0.43161964, 0.43161964, 0.435502  , 0.435502  ,\n",
       "        0.644757  , 0.5942825 , 0.43938434, 0.43938434, 0.4432667 ,\n",
       "        0.43938434, 0.43938434, 0.4432667 , 0.43938434, 0.43938434,\n",
       "        0.43938434, 0.4432667 , 0.44714907, 0.4432667 , 0.43938434,\n",
       "        0.4432667 , 0.42957366, 0.42957366, 0.43273774, 0.43273774,\n",
       "        0.43345603, 0.43117705, 0.4350594 , 0.4350594 , 0.43117705,\n",
       "        0.4350594 , 0.43161964, 0.4338986 , 0.66309327, 0.5655026 ,\n",
       "        0.43938434, 0.43938434, 0.4432667 , 0.43938434, 0.4432667 ,\n",
       "        0.4416633 , 0.43938434, 0.43938434, 0.4432667 , 0.4432667 ,\n",
       "        0.4432667 , 0.44714907, 0.45103142, 0.45103142, 0.43117705,\n",
       "        0.43229514, 0.43273774, 0.4338986 , 0.43117705, 0.43161964,\n",
       "        0.435502  , 0.43161964, 0.435502  , 0.435502  , 0.43161964,\n",
       "        0.435502  , 0.69451314, 0.558856  , 0.43894175, 0.43894175,\n",
       "        0.4428241 , 0.4432667 , 0.4432667 , 0.4432667 , 0.4432667 ,\n",
       "        0.44714907, 0.4432667 , 0.44714907, 0.44714907, 0.45103142,\n",
       "        0.45103142, 0.45103142, 0.435502  , 0.435502  , 0.43161964,\n",
       "        0.43161964, 0.43161964, 0.4338986 , 0.435502  , 0.43161964,\n",
       "        0.435502  , 0.43822354, 0.435502  , 0.43938434, 0.7096427 ,\n",
       "        0.5503731 , 0.43894175, 0.44122073, 0.44238153, 0.4462639 ,\n",
       "        0.4462639 , 0.44714907, 0.4432667 , 0.4432667 , 0.44714907,\n",
       "        0.44714907, 0.44714907, 0.45103142, 0.45103142, 0.45058882,\n",
       "        0.43938434, 0.435502  , 0.435502  , 0.435502  , 0.43161964,\n",
       "        0.435502  , 0.43778095, 0.435502  , 0.43161964, 0.4343412 ,\n",
       "        0.43938434, 0.4428241 , 0.6929098 , 0.5655026 , 0.4432667 ,\n",
       "        0.4432667 , 0.4428241 , 0.44238153, 0.4462639 , 0.4428241 ,\n",
       "        0.4432667 , 0.44714907, 0.44714907, 0.45103142, 0.45103142,\n",
       "        0.45103142, 0.45103142, 0.44714907, 0.44714907, 0.43938434,\n",
       "        0.435502  , 0.43161964, 0.43161964, 0.435502  , 0.435502  ,\n",
       "        0.435502  , 0.43161964, 0.43161964, 0.43161964, 0.435502  ,\n",
       "        0.6486393 , 0.6108057 , 0.4432667 , 0.435502  , 0.4428241 ,\n",
       "        0.44238153, 0.44466043, 0.43894175, 0.4432667 , 0.4432667 ,\n",
       "        0.44714907, 0.45058882, 0.45014626, 0.45447117, 0.45103142,\n",
       "        0.45103142, 0.4432667 , 0.435502  , 0.43938434, 0.43938434,\n",
       "        0.435502  , 0.43938434, 0.435502  , 0.435502  , 0.435502  ,\n",
       "        0.435502  , 0.43161964, 0.4343412 , 0.59272176, 0.67649126,\n",
       "        0.4432667 , 0.43894175, 0.4428241 , 0.44554564, 0.44394222,\n",
       "        0.43938434, 0.44714907, 0.4432667 , 0.4432667 , 0.44714907,\n",
       "        0.45058882, 0.45103142, 0.45103142, 0.45103142, 0.44714907,\n",
       "        0.4432667 , 0.4432667 , 0.43938434, 0.43938434, 0.43938434,\n",
       "        0.43938434, 0.435502  , 0.43938434, 0.435502  , 0.4343412 ,\n",
       "        0.4366201 , 0.5034665 , 0.60557234, 0.4432667 , 0.43938434,\n",
       "        0.4432667 , 0.4432667 , 0.4432667 , 0.4432667 , 0.4432667 ,\n",
       "        0.44714907, 0.44714907, 0.4432667 , 0.45103142, 0.45491377,\n",
       "        0.4587961 , 0.45491377, 0.44714907, 0.4432667 , 0.4432667 ,\n",
       "        0.43938434, 0.43938434, 0.43938434, 0.43938434, 0.43938434,\n",
       "        0.435502  , 0.435502  , 0.435502  , 0.43822354, 0.43938434,\n",
       "        0.4432667 , 0.4432667 , 0.4432667 , 0.4432667 , 0.4432667 ,\n",
       "        0.44714907, 0.44714907, 0.45103142, 0.45058882, 0.44714907,\n",
       "        0.45103142, 0.45103142, 0.45763528, 0.45331037, 0.45491377,\n",
       "        0.45103142, 0.44714907, 0.4432667 , 0.4432667 , 0.4432667 ,\n",
       "        0.4416633 , 0.43938434, 0.435502  , 0.43938434, 0.43938434,\n",
       "        0.43938434, 0.43938434, 0.4432667 , 0.44714907, 0.44714907,\n",
       "        0.44714907, 0.4432667 , 0.4432667 , 0.45103142, 0.45103142,\n",
       "        0.45103142, 0.45103142, 0.45103142, 0.45103142, 0.45491377,\n",
       "        0.45375293, 0.45375293, 0.45103142, 0.44714907, 0.4432667 ,\n",
       "        0.4432667 , 0.4432667 , 0.43938434, 0.44714907, 0.4432667 ,\n",
       "        0.43938434, 0.43822354, 0.44050243, 0.4416633 , 0.43938434,\n",
       "        0.4432667 , 0.44714907, 0.44714907, 0.44714907, 0.44714907,\n",
       "        0.45103142, 0.44714907, 0.45103142, 0.45103142, 0.45103142,\n",
       "        0.45491377, 0.4498706 , 0.4521922 , 0.45491377, 0.4587961 ,\n",
       "        0.45491377, 0.45103142, 0.4432667 , 0.4432667 , 0.4432667 ,\n",
       "        0.43938434, 0.44714907, 0.44714907, 0.4432667 , 0.43822354,\n",
       "        0.43822354, 0.4443848 , 0.449428  , 0.449428  , 0.4498706 ,\n",
       "        0.44598824, 0.45103142, 0.44714907, 0.44714907, 0.45103142,\n",
       "        0.45103142, 0.45103142, 0.45103142, 0.45491377, 0.45603186,\n",
       "        0.45331037, 0.45103142, 0.45763528, 0.45835352], dtype=float32),\n",
       " Array([0.26651487, 0.26811823, 0.27544034, 0.28320506, 0.28320506,\n",
       "        0.28320506, 0.29096976, 0.2870874 , 0.29096976, 0.2948521 ,\n",
       "        0.29873446, 0.3026168 , 0.30649918, 0.30649918, 0.30649918,\n",
       "        0.31038153, 0.30738434, 0.31814623, 0.31903142, 0.32591093,\n",
       "        0.32202858, 0.32202858, 0.32591093, 0.32591093, 0.33367565,\n",
       "        0.33783364, 0.341716  , 0.341716  , 0.26767564, 0.27771926,\n",
       "        0.2793227 , 0.2793227 , 0.2793227 , 0.2870874 , 0.2870874 ,\n",
       "        0.2870874 , 0.2948521 , 0.29873446, 0.3026168 , 0.3030594 ,\n",
       "        0.30649918, 0.30649918, 0.31038153, 0.31038153, 0.31038153,\n",
       "        0.31814623, 0.32202858, 0.32202858, 0.32202858, 0.32546836,\n",
       "        0.32591093, 0.3332331 , 0.33667284, 0.33739105, 0.33783364,\n",
       "        0.33783364, 0.27544034, 0.27888015, 0.27544034, 0.27588293,\n",
       "        0.28320506, 0.2870874 , 0.2870874 , 0.29096976, 0.2948521 ,\n",
       "        0.29873446, 0.29917705, 0.30350196, 0.30649918, 0.30649918,\n",
       "        0.30649918, 0.30993897, 0.31382132, 0.31954   , 0.31998256,\n",
       "        0.3238649 , 0.31998256, 0.32890812, 0.3350694 , 0.3339513 ,\n",
       "        0.33783364, 0.33783364, 0.33783364, 0.33783364, 0.27544034,\n",
       "        0.27544034, 0.27588293, 0.2793227 , 0.2793227 , 0.28320506,\n",
       "        0.2870874 , 0.29096976, 0.29873446, 0.2948521 , 0.3026168 ,\n",
       "        0.3026168 , 0.3026168 , 0.30649918, 0.3026168 , 0.30605662,\n",
       "        0.31382132, 0.31998256, 0.32342234, 0.32342234, 0.32846555,\n",
       "        0.33006895, 0.3339513 , 0.3339513 , 0.3339513 , 0.3339513 ,\n",
       "        0.3339513 , 0.33623028, 0.271558  , 0.27200058, 0.27244315,\n",
       "        0.2763255 , 0.2793227 , 0.2793227 , 0.28320506, 0.29096976,\n",
       "        0.2948521 , 0.3005708 , 0.30217424, 0.3026168 , 0.30377764,\n",
       "        0.3026168 , 0.31038153, 0.31426388, 0.31770366, 0.31954   ,\n",
       "        0.3245832 , 0.3261866 , 0.3261866 , 0.33006895, 0.33783364,\n",
       "        0.3339513 , 0.3339513 , 0.3339513 , 0.33783364, 0.33551195,\n",
       "        0.27111542, 0.271558  , 0.27544034, 0.2793227 , 0.2793227 ,\n",
       "        0.2793227 , 0.28320506, 0.29096976, 0.29440954, 0.30173165,\n",
       "        0.3557701 , 0.39700073, 0.41917667, 0.39191478, 0.31774634,\n",
       "        0.31038153, 0.31726107, 0.32230425, 0.3261866 , 0.3261866 ,\n",
       "        0.33006895, 0.3339513 , 0.3339513 , 0.33623028, 0.33623028,\n",
       "        0.3327905 , 0.3350694 , 0.33551195, 0.26767564, 0.271558  ,\n",
       "        0.271558  , 0.27544034, 0.2793227 , 0.28320506, 0.2870874 ,\n",
       "        0.2998953 , 0.4113693 , 0.42850214, 0.36397737, 0.30382034,\n",
       "        0.30377764, 0.34840524, 0.4718447 , 0.35460928, 0.32186165,\n",
       "        0.325744  , 0.3261866 , 0.3261866 , 0.33006895, 0.33006895,\n",
       "        0.3339513 , 0.3339513 , 0.33483645, 0.3327905 , 0.33118704,\n",
       "        0.3316296 , 0.27200058, 0.271558  , 0.271558  , 0.27544034,\n",
       "        0.2793227 , 0.2870874 , 0.28436586, 0.50231344, 0.32555377,\n",
       "        0.29873446, 0.30377764, 0.3026168 , 0.3026168 , 0.3026168 ,\n",
       "        0.31542468, 0.49290258, 0.34015524, 0.32530144, 0.32530144,\n",
       "        0.3335087 , 0.33006895, 0.3261866 , 0.33006895, 0.3327905 ,\n",
       "        0.3332331 , 0.3316296 , 0.33118704, 0.33118704, 0.27244315,\n",
       "        0.27200058, 0.271558  , 0.27544034, 0.2793227 , 0.2827625 ,\n",
       "        0.28364766, 0.34612638, 0.2948521 , 0.29873446, 0.29873446,\n",
       "        0.3026168 , 0.3026168 , 0.30605662, 0.31337872, 0.35528478,\n",
       "        0.44778967, 0.32530144, 0.3291838 , 0.32962635, 0.32846555,\n",
       "        0.33118704, 0.33118704, 0.33118704, 0.3350694 , 0.3316296 ,\n",
       "        0.3327905 , 0.3305115 , 0.271558  , 0.271558  , 0.271558  ,\n",
       "        0.27544034, 0.27544034, 0.2793227 , 0.2870874 , 0.29096976,\n",
       "        0.29096976, 0.2948521 , 0.29873446, 0.30445313, 0.30789292,\n",
       "        0.31177527, 0.31065717, 0.3149821 , 0.47621238, 0.32346505,\n",
       "        0.3261866 , 0.3261866 , 0.32502577, 0.32846555, 0.32846555,\n",
       "        0.32890812, 0.32890812, 0.33439386, 0.33439386, 0.3305115 ,\n",
       "        0.26811823, 0.271558  , 0.27544034, 0.27544034, 0.27544034,\n",
       "        0.2870874 , 0.2948521 , 0.2948521 , 0.2948521 , 0.2948521 ,\n",
       "        0.2948521 , 0.30561402, 0.30561402, 0.30789292, 0.31293616,\n",
       "        0.3149821 , 0.43078104, 0.37290296, 0.3261866 , 0.3261866 ,\n",
       "        0.3261866 , 0.3273047 , 0.32846555, 0.33006895, 0.33006895,\n",
       "        0.33006895, 0.3327905 , 0.33623028, 0.26651487, 0.271558  ,\n",
       "        0.271558  , 0.27544034, 0.2793227 , 0.28753   , 0.2952947 ,\n",
       "        0.29573727, 0.29873446, 0.30217424, 0.30877808, 0.31565762,\n",
       "        0.31565762, 0.31565762, 0.31726107, 0.32230425, 0.3724177 ,\n",
       "        0.4326601 , 0.33006895, 0.33006895, 0.32342234, 0.32774726,\n",
       "        0.3273047 , 0.32774726, 0.32846555, 0.32890812, 0.33118704,\n",
       "        0.3339513 , 0.27039722, 0.271558  , 0.27544034, 0.27544034,\n",
       "        0.2793227 , 0.29185492, 0.29873446, 0.29873446, 0.30217424,\n",
       "        0.30649918, 0.31221783, 0.31565762, 0.31654277, 0.31770366,\n",
       "        0.32114342, 0.3231894 , 0.3371581 , 0.4816554 , 0.32778996,\n",
       "        0.33006895, 0.32502577, 0.32591093, 0.32591093, 0.32890812,\n",
       "        0.32846555, 0.3261866 , 0.33006895, 0.3339513 , 0.27516472,\n",
       "        0.27472213, 0.27472213, 0.27544034, 0.2793227 , 0.29096976,\n",
       "        0.2948521 , 0.3026168 , 0.3026168 , 0.3026168 , 0.30993897,\n",
       "        0.31266043, 0.31814623, 0.31814623, 0.31814623, 0.3231894 ,\n",
       "        0.32046786, 0.48441964, 0.33006895, 0.3261866 , 0.32230425,\n",
       "        0.3273047 , 0.32774726, 0.3273047 , 0.32890812, 0.3261866 ,\n",
       "        0.3339513 , 0.3339513 , 0.27356124, 0.2774436 , 0.27516472,\n",
       "        0.27700102, 0.2827625 , 0.2905272 , 0.29873446, 0.3026168 ,\n",
       "        0.29873446, 0.30649918, 0.31426388, 0.31426388, 0.31426388,\n",
       "        0.31814623, 0.31814623, 0.31770366, 0.32002527, 0.4805373 ,\n",
       "        0.33006895, 0.3261866 , 0.32230425, 0.32502577, 0.3273047 ,\n",
       "        0.33118704, 0.33234793, 0.33006895, 0.3305115 , 0.3339513 ,\n",
       "        0.27267608, 0.27700102, 0.27472213, 0.27588293, 0.2816016 ,\n",
       "        0.2948521 , 0.29873446, 0.3026168 , 0.3026168 , 0.30649918,\n",
       "        0.31038153, 0.31426388, 0.31426388, 0.31814623, 0.31814623,\n",
       "        0.31814623, 0.35156938, 0.4610401 , 0.32662916, 0.3261866 ,\n",
       "        0.32230425, 0.3238649 , 0.32342234, 0.3245832 , 0.33118704,\n",
       "        0.32890812, 0.3332331 , 0.3387188 , 0.27267608, 0.27427956,\n",
       "        0.2793227 , 0.2793227 , 0.2870874 , 0.29096976, 0.29917705,\n",
       "        0.30350196, 0.3026168 , 0.30649918, 0.30765998, 0.31038153,\n",
       "        0.31426388, 0.31586727, 0.31814623, 0.3165855 , 0.40816247,\n",
       "        0.39851868, 0.32778996, 0.3261866 , 0.32114342, 0.3238649 ,\n",
       "        0.3273047 , 0.32230425, 0.3273047 , 0.33118704, 0.3316296 ,\n",
       "        0.3309541 , 0.27427956, 0.27544034, 0.2793227 , 0.2793227 ,\n",
       "        0.2870874 , 0.2948521 , 0.29873446, 0.29961962, 0.30350196,\n",
       "        0.30582365, 0.35437635, 0.4265415 , 0.44523504, 0.42126542,\n",
       "        0.4340733 , 0.4352341 , 0.55278784, 0.4654505 , 0.39771894,\n",
       "        0.34840524, 0.32114342, 0.3273047 , 0.3231894 , 0.3231894 ,\n",
       "        0.32202858, 0.32546836, 0.3320722 , 0.3332331 , 0.27544034,\n",
       "        0.27427956, 0.28020787, 0.28409022, 0.28797257, 0.29573727,\n",
       "        0.29917705, 0.30350196, 0.30810258, 0.45143905, 0.41132656,\n",
       "        0.31474918, 0.31542468, 0.31930706, 0.32202858, 0.4328271 ,\n",
       "        0.3872715 , 0.33599728, 0.38566813, 0.4269414 , 0.4654505 ,\n",
       "        0.39307567, 0.31886446, 0.32202858, 0.32591093, 0.32591093,\n",
       "        0.3293507 , 0.3327905 , 0.27588293, 0.27860448, 0.28248683,\n",
       "        0.2870874 , 0.28753   , 0.29573727, 0.2973407 , 0.30350196,\n",
       "        0.45139632, 0.34456563, 0.3088208 , 0.31154233, 0.31154233,\n",
       "        0.31702808, 0.40356186, 0.422531  , 0.321586  , 0.3243075 ,\n",
       "        0.32890812, 0.32774726, 0.32546836, 0.39419377, 0.5329724 ,\n",
       "        0.32591093, 0.32591093, 0.32591093, 0.33118704, 0.3339513 ,\n",
       "        0.28132597, 0.2852083 , 0.28797257, 0.29096976, 0.29185492,\n",
       "        0.2952947 , 0.29573727, 0.29917705, 0.36397737, 0.4684477 ,\n",
       "        0.3670173 , 0.33836165, 0.35893422, 0.4598793 , 0.39896128,\n",
       "        0.32502577, 0.32342234, 0.32546836, 0.32591093, 0.32818985,\n",
       "        0.32818985, 0.3293507 , 0.3239076 , 0.32707176, 0.32707176,\n",
       "        0.32591093, 0.3327905 , 0.3339513 , 0.2852083 , 0.2852083 ,\n",
       "        0.28909066, 0.2941339 , 0.2941339 , 0.2975737 , 0.2959702 ,\n",
       "        0.29873446, 0.30377764, 0.30810258, 0.37606704, 0.41793045,\n",
       "        0.38066766, 0.3231894 , 0.31426388, 0.32202858, 0.3243075 ,\n",
       "        0.32202858, 0.32202858, 0.32591093, 0.32591093, 0.32591093,\n",
       "        0.3309541 , 0.32707176, 0.3309541 , 0.32979327, 0.3293507 ,\n",
       "        0.3261866 , 0.28909066, 0.2852083 , 0.29025152, 0.29069412,\n",
       "        0.2945765 , 0.2964128 , 0.2959702 , 0.2975737 , 0.3026168 ,\n",
       "        0.3026168 , 0.30377764, 0.30765998, 0.31154233, 0.31426388,\n",
       "        0.31426388, 0.31426388, 0.31814623, 0.32202858, 0.32591093,\n",
       "        0.32591093, 0.32979327, 0.32979327, 0.32979327, 0.32979327,\n",
       "        0.32979327, 0.3316296 , 0.33118704, 0.3339513 , 0.28909066,\n",
       "        0.2941339 , 0.29185492, 0.2941339 , 0.2952947 , 0.29873446,\n",
       "        0.30145603, 0.30489573, 0.29873446, 0.3026168 , 0.30765998,\n",
       "        0.31426388, 0.31426388, 0.31426388, 0.31426388, 0.31426388,\n",
       "        0.31814623, 0.32202858, 0.32979327, 0.32591093, 0.32591093,\n",
       "        0.32979327, 0.33367565, 0.337558  , 0.337558  , 0.33118704,\n",
       "        0.33118704, 0.3350694 , 0.2886481 , 0.29069412, 0.29573727,\n",
       "        0.2948521 , 0.2948521 , 0.2982919 , 0.30350196, 0.3030594 ,\n",
       "        0.3026168 , 0.30694178, 0.31038153, 0.31426388, 0.31426388,\n",
       "        0.31426388, 0.31814623, 0.32202858, 0.31814623, 0.32202858,\n",
       "        0.32979327, 0.32591093, 0.33367565, 0.33411825, 0.33367565,\n",
       "        0.33367565, 0.3409978 , 0.3428341 , 0.33895174, 0.33667284,\n",
       "        0.2882055 , 0.29208785, 0.292973  , 0.29573727, 0.2952947 ,\n",
       "        0.2948521 , 0.30350196, 0.30694178, 0.31038153, 0.31038153,\n",
       "        0.31038153, 0.31426388, 0.31038153, 0.31470647, 0.31903142,\n",
       "        0.32247117, 0.32247117, 0.31814623, 0.32979327, 0.32979327,\n",
       "        0.33483645, 0.34260115, 0.337558  , 0.337558  , 0.3428341 ,\n",
       "        0.34671646, 0.34144035, 0.3398369 , 0.28980896, 0.28980896,\n",
       "        0.29369134, 0.29573727, 0.29873446, 0.3030594 , 0.30738434,\n",
       "        0.30649918, 0.31038153, 0.31038153, 0.31426388, 0.31814623,\n",
       "        0.31998256, 0.32202858, 0.31858882, 0.31903142, 0.32202858,\n",
       "        0.32546836, 0.32591093, 0.33367565, 0.33483645, 0.3387188 ,\n",
       "        0.337558  , 0.3398369 , 0.33895174, 0.3398369 , 0.3453227 ,\n",
       "        0.3453227 , 0.29096976, 0.29096976, 0.2948521 , 0.29440954,\n",
       "        0.29873446, 0.3030594 , 0.30694178, 0.31038153, 0.31038153,\n",
       "        0.31038153, 0.31038153, 0.31770366, 0.32042515, 0.32202858,\n",
       "        0.32247117, 0.32202858, 0.32202858, 0.32202858, 0.32591093,\n",
       "        0.32979327, 0.33367565, 0.33367565, 0.34144035, 0.34443754,\n",
       "        0.3428341 , 0.34488013, 0.34488013, 0.34443754], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw_digits_X[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ANN model on handwritten whiteboard digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on handwritten digits % =  11.11111111111111\n"
     ]
    }
   ],
   "source": [
    "n.test(hw_digits_X, hw_digits_Y)\n",
    "hw_whiteboard_acc = n.evaluate(n.results)\n",
    "\n",
    "print('Accuracy on handwritten digits % = ', hw_whiteboard_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions: \n",
      "Predicted:  9.0  Input:  9.0\n",
      "\n",
      "Incorrect predictions: \n",
      "Predicted:  9.0  Input:  1.0\n",
      "Predicted:  9.0  Input:  2.0\n",
      "Predicted:  9.0  Input:  3.0\n",
      "Predicted:  9.0  Input:  7.0\n",
      "Predicted:  9.0  Input:  6.0\n",
      "Predicted:  9.0  Input:  4.0\n",
      "Predicted:  9.0  Input:  5.0\n",
      "Predicted:  9.0  Input:  8.0\n"
     ]
    }
   ],
   "source": [
    "show_results(n.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidently the model does not perform well on my own handwritten digits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test augmented ANN model on whiteboard digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling data...\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [591.36009738]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [231.07263884]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [125.16206495]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [69.04568957]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [43.1509124]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [28.80025577]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [20.04240112]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [14.38466931]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [10.97501542]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [8.82229967]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [7.30675144]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [6.21275459]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [5.34079095]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [4.70078002]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [4.18758923]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [3.76756355]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [3.40020381]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [3.11969484]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [2.89213621]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [2.68724144]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [2.53012479]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [2.39181529]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [2.26546026]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [2.15279156]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [2.05255841]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [1.96094159]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [1.87331757]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [1.78824408]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [1.70738185]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [1.63471578]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [1.56933271]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [1.50822828]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [1.45289084]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [1.40407718]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [1.36041027]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [1.32101577]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [1.28534698]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [1.2531143]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [1.22424028]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [1.1976059]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [1.1707775]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [1.14447629]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [1.11889537]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [1.09463423]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [1.07163867]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [1.04911238]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [1.0254978]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [1.00126721]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [0.97811212]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [0.95646101]\n",
      "Shuffling data...\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [679.34797724]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [315.40767276]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [188.20003337]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [113.88172715]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [66.32980074]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [41.47759297]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [28.75513079]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [20.66894357]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [16.04885887]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [13.00265307]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [10.90204709]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [9.38005942]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [8.21702278]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [7.25495065]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [6.4039371]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [5.65416403]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [5.06661969]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [4.60355393]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [4.24272122]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [3.97818089]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [3.73447373]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [3.51990119]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [3.32961644]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [3.15660044]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [2.99909551]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [2.85150064]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [2.69569901]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [2.56212807]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [2.46075692]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [2.37448842]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [2.29447687]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [2.21592477]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [2.14162236]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [2.07370001]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [2.01210151]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [1.95594373]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [1.90414595]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [1.85664356]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [1.8142405]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [1.76571031]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [1.69815377]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [1.6363017]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [1.58681977]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [1.54335793]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [1.50349389]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [1.46643412]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [1.43186109]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [1.39959983]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [1.3695241]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [1.34151271]\n",
      "Shuffling data...\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [784.91871529]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [389.81744436]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [225.47540757]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [141.58909784]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [87.32107302]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [55.16094677]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [36.78699371]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [25.06096843]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [17.77393565]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [13.51365674]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [10.98525162]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [9.27468601]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [8.01754854]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [7.02605689]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [6.22318849]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [5.56119475]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [5.03636611]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [4.61716808]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [4.2628521]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [3.96847073]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [3.71816235]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [3.50227679]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [3.31306201]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [3.14173331]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [2.9915783]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [2.8600537]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [2.73775158]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [2.63341529]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [2.53598345]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [2.43700648]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [2.35068891]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [2.26643419]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [2.18470632]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [2.1144867]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [2.0527748]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [1.99560335]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [1.94187982]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [1.8914191]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [1.84412206]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [1.79954536]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [1.75677195]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [1.71496007]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [1.67348885]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [1.63259581]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [1.59429609]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [1.55915336]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [1.52676663]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [1.49674202]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [1.4685045]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [1.44108272]\n",
      "Shuffling data...\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [813.5729468]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [438.5014494]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [264.40463208]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [155.20038026]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [92.72780128]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [54.39459422]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [34.1684916]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [22.83111712]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [16.29623279]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [12.44992836]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [9.93034544]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [8.33741788]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [7.1892709]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [6.3074596]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [5.69962279]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [5.19195981]\n",
      "Training epoch#:  16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors (SSE):  [4.7521984]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [4.39552759]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [4.08771086]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [3.82182265]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [3.58852319]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [3.38067578]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [3.19380226]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [3.03566172]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [2.90113349]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [2.78668706]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [2.68485804]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [2.58925962]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [2.49981526]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [2.41767393]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [2.33836335]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [2.26597373]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [2.19157086]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [2.11897771]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [2.05297382]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [1.99418769]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [1.94076627]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [1.89159577]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [1.84548569]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [1.80207594]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [1.76066375]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [1.72041726]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [1.68171002]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [1.64478476]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [1.60976198]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [1.57678257]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [1.54581413]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [1.51642899]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [1.48822767]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [1.46145153]\n"
     ]
    }
   ],
   "source": [
    "ann_whiteboard_aug_results = []\n",
    "\n",
    "rotations = [10, 20, 30, 45]\n",
    "\n",
    "for num in rotations:\n",
    "     ## Clear and generate data again\n",
    "    mini_training_data = p.generate_mini_data(train_data_list, 1500)\n",
    "\n",
    "    X_train, y_train = p.preprocess_data(mini_training_data)\n",
    "    \n",
    "    # train and test model on whiteboard digits\n",
    "    model = a.fit_augmented_model(X_train, y_train, hw_digits_X, hw_digits_Y, 1500, num)\n",
    "    \n",
    "    ann_whiteboard_aug_results.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11.11111111111111, 11.11111111111111, 22.22222222222222, 11.11111111111111]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_whiteboard_aug_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ANN model with edited whiteboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hw_edited/*.png\n",
      "Loading...  hw_edited/img_1.png\n",
      "Loading...  hw_edited/img_2.png\n",
      "Loading...  hw_edited/img_3.png\n",
      "Loading...  hw_edited/img_7.png\n",
      "Loading...  hw_edited/img_6.png\n",
      "Loading...  hw_edited/img_4.png\n",
      "Loading...  hw_edited/img_5.png\n",
      "Loading...  hw_edited/img_8.png\n",
      "Loading...  hw_edited/img_9.png\n"
     ]
    }
   ],
   "source": [
    "hw_edited_X, hw_edited_Y = get_my_test_data(\"hw_edited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.asfarray(hw_edited_X[3].flatten().reshape((28,28))), cmap='Greys', interpolation='None')\n",
    "\n",
    "plt.title('Whiteboard edited')\n",
    "plt.savefig('hw-edited.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks cleaner and noise has clearly been reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array([0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.05270588,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.09152941, 1.        , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        1.        , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 1.        , 0.01388235,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.97282356, 0.02164706, 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.92235297,\n",
       "        0.04494118, 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.8447059 , 0.01776471, 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.84082353, 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01776471, 0.9068235 , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.08764706, 0.8563529 , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.11482353, 0.5807059 ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.17694119, 0.49529412, 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.23129413,\n",
       "        0.40988237, 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.3322353 , 0.32447058, 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.38658825, 0.27400002, 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.4292941 , 0.208     ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.50305885, 0.1924706 , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.5418824 ,\n",
       "        0.17305884, 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.50305885, 0.208     , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.3982353 , 0.31670588, 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.27788237, 0.4875294 ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.08376471, 0.31282353, 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      ], dtype=float32),\n",
       " Array([0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.11094118, 0.17305884, 0.09152941, 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.16917649, 0.21964706, 0.02164706, 0.01      ,\n",
       "        0.01      , 0.01      , 0.33611766, 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.5341177 , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.3982353 , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.23129413, 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.32058823, 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.17694119, 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01388235,\n",
       "        0.17694119, 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.3322353 , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.33611766, 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.31670588,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.2507059 , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.08376471,\n",
       "        0.05658824, 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.17305884, 0.22741178, 0.13811766,\n",
       "        0.16141178, 0.15364707, 0.5574118 , 0.23905884, 0.05658824,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.26235294, 0.13035294,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.15364707,\n",
       "        0.02941176, 0.01      , 0.03717647, 0.15364707, 0.27788237,\n",
       "        0.06823529, 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.27788237, 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.08764706, 0.14200002, 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.07600001, 0.5845882 ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01388235, 0.31670588,\n",
       "        0.01      , 0.01      , 0.01      , 0.27788237, 0.08764706,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.04105882, 0.16141178,\n",
       "        0.04882353, 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      ], dtype=float32)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw_edited_X, hw_edited_Y = map_target_to_output_layer(hw_edited_X, hw_edited_Y)\n",
    "hw_edited_X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on edited handwritten digits % =  22.22222222222222\n"
     ]
    }
   ],
   "source": [
    "n.test(hw_edited_X, hw_edited_Y)\n",
    "\n",
    "hw_edited_acc = n.evaluate(n.results)\n",
    "\n",
    "print('Accuracy on edited handwritten digits % = ', hw_edited_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions: \n",
      "Predicted:  1.0  Input:  1.0\n",
      "Predicted:  2.0  Input:  2.0\n",
      "\n",
      "Incorrect predictions: \n",
      "Predicted:  5.0  Input:  3.0\n",
      "Predicted:  5.0  Input:  7.0\n",
      "Predicted:  5.0  Input:  6.0\n",
      "Predicted:  5.0  Input:  4.0\n",
      "Predicted:  7.0  Input:  5.0\n",
      "Predicted:  5.0  Input:  8.0\n",
      "Predicted:  7.0  Input:  9.0\n"
     ]
    }
   ],
   "source": [
    "show_results(n.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No improvement really... Let's test using the augmented model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize difference in noise between GIMP, whiteboard and edited whiteboard images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3)\n",
    "\n",
    "ax1.imshow(np.asfarray(gimp_test_X[1].flatten().reshape((28,28))), cmap='Greys', interpolation='None')\n",
    "ax1.set_title('GIMP')\n",
    "\n",
    "ax2.imshow(np.asfarray(hw_digits_X[4].flatten().reshape((28,28))), cmap='Greys', interpolation='None')\n",
    "ax2.set_title('Whiteboard')\n",
    "\n",
    "ax3.imshow(np.asfarray(hw_edited_X[3].flatten().reshape((28,28))), cmap='Greys', interpolation='None')\n",
    "ax3.set_title('Whiteboard edited')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig('noise-comparison.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test augmented ANN model on edited whiteboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling data...\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [570.6804368]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [237.8607037]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [135.21610905]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [78.11317215]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [47.81774248]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [30.68618486]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [21.2201159]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [15.78434218]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [12.30431548]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [9.83105552]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [8.03771913]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [6.71122169]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [5.72658705]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [5.00298575]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [4.45393196]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [4.0285699]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [3.68818275]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [3.40333423]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [3.1569404]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [2.93936744]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [2.74688023]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [2.57597806]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [2.42437304]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [2.29032647]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [2.1719028]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [2.06681827]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [1.97312728]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [1.88949771]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [1.81434329]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [1.74591328]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [1.68292602]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [1.62463663]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [1.5706216]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [1.5204396]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [1.47340362]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [1.42876859]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [1.38609017]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [1.34508198]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [1.30603704]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [1.269442]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [1.2354468]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [1.20390118]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [1.17450635]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [1.14695843]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [1.12100218]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [1.09646672]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [1.07330654]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [1.05128035]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [1.02980396]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [1.00889325]\n",
      "Shuffling data...\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [629.03532904]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [276.74216501]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [162.69942081]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [90.39515214]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [52.72642902]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [33.63512527]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [22.82535075]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [15.99156476]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [11.97069152]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [9.4559249]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [7.77113932]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [6.54700686]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [5.65605262]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [4.99956271]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [4.46206682]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [4.03198709]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [3.68436337]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [3.39656122]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [3.15548794]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [2.95168888]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [2.77586514]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [2.62133599]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [2.48409126]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [2.36170784]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [2.25168975]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [2.15242788]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [2.06247501]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [1.98014865]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [1.90428737]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [1.83430807]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [1.76983544]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [1.71039147]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [1.65547581]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [1.60469933]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [1.55779127]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [1.51444981]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [1.47431706]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [1.43707107]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [1.40245539]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [1.37015483]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [1.33974804]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [1.31099586]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [1.28389983]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [1.25844609]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [1.23456765]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [1.21221024]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [1.19127316]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [1.17134938]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [1.15176117]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [1.13213785]\n",
      "Shuffling data...\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [749.02437795]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [394.91741395]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [249.90939533]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [158.57513599]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [99.52356019]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [63.81442177]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [41.12524056]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [27.42327019]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [19.51096338]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [14.91421499]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [11.83085043]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [9.60252727]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [8.10635608]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [7.01281627]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [6.17762556]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [5.52356577]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [4.98391747]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [4.53200887]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [4.15527932]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [3.84569734]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [3.58736256]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [3.36610295]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [3.17306976]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [3.0027518]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [2.84921367]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [2.7092856]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [2.58142618]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [2.46494274]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [2.3590645]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [2.26235514]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [2.17393185]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [2.0936808]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [2.02128358]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [1.95599617]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [1.89644604]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [1.84166889]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [1.7908441]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [1.74217293]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [1.69522521]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [1.64986919]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [1.60670549]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [1.56632733]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [1.52876634]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [1.49374422]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [1.46076363]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [1.42935001]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [1.39922935]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [1.37024989]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [1.34231008]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [1.31542005]\n",
      "Shuffling data...\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [850.27566331]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [472.14229122]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [314.77170297]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [201.70521062]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [131.5464589]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [82.1498863]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [51.80443494]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [33.09585902]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [22.4204346]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [16.85724388]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [13.33773719]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [10.82677773]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [8.99678635]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [7.74920606]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [6.8394315]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [6.12555238]\n",
      "Training epoch#:  16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors (SSE):  [5.54286202]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [5.07398727]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [4.67755991]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [4.34205393]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [4.05529442]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [3.80724203]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [3.5886443]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [3.38890918]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [3.20627459]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [3.04556166]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [2.90103256]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [2.77897688]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [2.67378602]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [2.56988751]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [2.47391759]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [2.3927531]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [2.31602399]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [2.24526901]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [2.18043803]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [2.12079145]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [2.06555265]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [2.01385948]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [1.96467288]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [1.9171033]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [1.87248283]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [1.83187981]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [1.79357743]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [1.75736218]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [1.72297203]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [1.69019401]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [1.65893865]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [1.62918989]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [1.60091777]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [1.57407353]\n"
     ]
    }
   ],
   "source": [
    "aug_whiteboard_edited_results = []\n",
    "\n",
    "rotations = [10, 20, 30, 45]\n",
    "\n",
    "for num in rotations:\n",
    "     ## Clear and generate data again\n",
    "    mini_training_data = p.generate_mini_data(train_data_list, 1500)\n",
    "\n",
    "    X_train, y_train = p.preprocess_data(mini_training_data)\n",
    "    \n",
    "    # train and test model on edited whiteboard digits\n",
    "    model = a.fit_augmented_model(X_train, y_train, hw_edited_X, hw_edited_Y, 1500, num)\n",
    "    \n",
    "    aug_whiteboard_edited_results.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22.22222222222222, 22.22222222222222, 0.0, 11.11111111111111]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_whiteboard_edited_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Preprocess(is_neural=False) # Preprocess object for kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_training_data = p.generate_mini_data(train_data_list, 1500)\n",
    "X_train, y_train = p.preprocess_data(mini_training_data)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GIMP digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gimp/*.png\n",
      "Loading...  gimp/gimp_2.png\n",
      "Loading...  gimp/gimo_6.png\n",
      "Loading...  gimp/gimp_3.png\n",
      "Loading...  gimp/gimp_1.png\n",
      "Loading...  gimp/gimp_0.png\n",
      "Loading...  gimp/gimp_4.png\n",
      "Loading...  gimp/gimp_5.png\n",
      "Loading...  gimp/gimp_7.png\n",
      "Loading...  gimp/gimp_8.png\n",
      "Loading...  gimp/gimp_9.png\n"
     ]
    }
   ],
   "source": [
    "gimp_test_X, gimp_test_y = get_my_test_data(\"gimp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test kNN on GIMP digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Testing complete!\n"
     ]
    }
   ],
   "source": [
    "knn = kNN(X_train, y_train, k=3, weighted=True, sim=cosine_similarity)\n",
    "knn.test(gimp_test_X, gimp_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.0\n"
     ]
    }
   ],
   "source": [
    "gimp_knn_acc = knn.evaluate(knn.results)\n",
    "print(gimp_knn_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions: \n",
      "Predicted:  3  Input:  3\n",
      "Predicted:  1  Input:  1\n",
      "Predicted:  0  Input:  0\n",
      "Predicted:  4  Input:  4\n",
      "Predicted:  7  Input:  7\n",
      "Predicted:  8  Input:  8\n",
      "Predicted:  9  Input:  9\n",
      "\n",
      "Incorrect predictions: \n",
      "Predicted:  3  Input:  2\n",
      "Predicted:  0  Input:  6\n",
      "Predicted:  3  Input:  5\n"
     ]
    }
   ],
   "source": [
    "show_results(knn.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how the kNN performs on rotated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AugmentImages(is_neural=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling data...\n",
      "Testing...\n",
      "Testing complete!\n",
      "Shuffling data...\n",
      "Testing...\n",
      "Testing complete!\n",
      "Shuffling data...\n",
      "Testing...\n",
      "Testing complete!\n",
      "Shuffling data...\n",
      "Testing...\n",
      "Testing complete!\n"
     ]
    }
   ],
   "source": [
    "aug_gimp_knn_results = []\n",
    "\n",
    "rotations = [10, 20, 30, 45]\n",
    "\n",
    "for num in rotations:\n",
    "    ## Clear and generate data again\n",
    "    mini_training_data = p.generate_mini_data(train_data_list, 1500)\n",
    "\n",
    "    X_train, y_train = p.preprocess_data(mini_training_data)\n",
    "    \n",
    "    # train and test model on gimp digits\n",
    "    model = a.fit_augmented_model(X_train, y_train, gimp_test_X, gimp_test_y, 1500, num)\n",
    "    aug_gimp_knn_results.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[70.0, 70.0, 80.0, 90.0]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_gimp_knn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN on digits written on whiteboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hw_digits/*.png\n",
      "Loading...  hw_digits/img_1.png\n",
      "Loading...  hw_digits/img_2.png\n",
      "Loading...  hw_digits/img_3.png\n",
      "Loading...  hw_digits/img_7.png\n",
      "Loading...  hw_digits/img_6.png\n",
      "Loading...  hw_digits/img_4.png\n",
      "Loading...  hw_digits/img_5.png\n",
      "Loading...  hw_digits/img_8.png\n",
      "Loading...  hw_digits/img_9.png\n"
     ]
    }
   ],
   "source": [
    "hw_digits_X, hw_digits_Y = get_my_test_data(\"hw_digits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Testing complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = kNN(X_train, y_train, k=3, weighted=True, sim=cosine_similarity)\n",
    "knn.test(hw_digits_X, hw_digits_Y)\n",
    "\n",
    "knn_whiteboard_acc = knn.evaluate(knn.results)\n",
    "knn_whiteboard_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if augmented model performs better on whiteboard digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling data...\n",
      "Testing...\n",
      "Testing complete!\n",
      "Shuffling data...\n",
      "Testing...\n",
      "Testing complete!\n",
      "Shuffling data...\n",
      "Testing...\n",
      "Testing complete!\n",
      "Shuffling data...\n",
      "Testing...\n",
      "Testing complete!\n"
     ]
    }
   ],
   "source": [
    "aug_whiteboard_knn_results = []\n",
    "\n",
    "rotations = [10, 20, 30, 45]\n",
    "\n",
    "for num in rotations:\n",
    "    ## Clear and generate data again\n",
    "    mini_training_data = p.generate_mini_data(train_data_list, 1500)\n",
    "\n",
    "    X_train, y_train = p.preprocess_data(mini_training_data)\n",
    "    \n",
    "    model = a.fit_augmented_model(X_train, y_train, hw_digits_X, hw_digits_Y, 1500, num)\n",
    "    aug_whiteboard_knn_results.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22.22222222222222, 0.0, 11.11111111111111, 33.33333333333333]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_whiteboard_knn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN on edited whiteboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hw_edited/*.png\n",
      "Loading...  hw_edited/img_1.png\n",
      "Loading...  hw_edited/img_2.png\n",
      "Loading...  hw_edited/img_3.png\n",
      "Loading...  hw_edited/img_7.png\n",
      "Loading...  hw_edited/img_6.png\n",
      "Loading...  hw_edited/img_4.png\n",
      "Loading...  hw_edited/img_5.png\n",
      "Loading...  hw_edited/img_8.png\n",
      "Loading...  hw_edited/img_9.png\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = p.preprocess_data(mini_training_data)\n",
    "\n",
    "hw_edited_X, hw_edited_Y = get_my_test_data(\"hw_edited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Testing complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55.55555555555556"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = kNN(X_train, y_train, k=3, weighted=True, sim=cosine_similarity)\n",
    "knn.test(hw_edited_X, hw_edited_Y)\n",
    "\n",
    "knn_whiteboard_edited_acc = knn.evaluate(knn.results)\n",
    "knn_whiteboard_edited_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets test the augmented kNN on edited whiteboard digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling data...\n",
      "Testing...\n",
      "Testing complete!\n",
      "Shuffling data...\n",
      "Testing...\n",
      "Testing complete!\n",
      "Shuffling data...\n",
      "Testing...\n",
      "Testing complete!\n",
      "Shuffling data...\n",
      "Testing...\n",
      "Testing complete!\n"
     ]
    }
   ],
   "source": [
    "aug_knn_wh_edited_results = []\n",
    "\n",
    "rotations = [10, 20, 30, 45]\n",
    "\n",
    "for num in rotations:\n",
    "    ## Clear and generate data again\n",
    "    mini_training_data = p.generate_mini_data(train_data_list, 1500)\n",
    "\n",
    "    X_train, y_train = p.preprocess_data(mini_training_data)\n",
    "    \n",
    "    model = a.fit_augmented_model(X_train, y_train, hw_edited_X, hw_edited_Y, 1500, num)\n",
    "    aug_knn_wh_edited_results.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55.55555555555556, 44.44444444444444, 55.55555555555556, 66.66666666666666]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_knn_wh_edited_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
